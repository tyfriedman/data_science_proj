{
    "first_layer_size": 64,
    "num_hidden_layers": 2,
    "activation": "relu",
    "dropout_rate": 0,
    "optimizer": "adam",
    "learning_rate": 0.01,
    "batch_size": 32,
    "epochs": 50
}